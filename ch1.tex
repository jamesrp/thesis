%!TEX root = thesis.tex


\chapter{Introduction}
\label{chap:introduction}

This thesis studies three problems in probability and optimization.
In this introduction, we give an extended abstract of each chapter, and give some context and motivation.
Chapter \ref{chap:bootstrap} studies bootstrap percolation, a probabilistic model of nucleation and growth.
Chapters \ref{chap:kicover} and \ref{chap:cube} apply sums of squares approximations to combinatorial optimization.
Chapter \ref{chap:matchings} studies the representation theory of the set of matchings and is an offshoot of the work in Chapter \ref{chap:cube}.

\section{Bootstrap Percolation on the Hamming Torus}
Chapter \ref{chap:bootstrap} is taken from a paper coauthored with Janko Gravner, Christopher Hoffman, and Davis Sivakoff, and submitted to \emph{Annals of Applied Probability}. %FIXME
It investigates the critical behavior of bootstrap percolation on the Hamming torus.

\subsection{Problem Description}
\label{section:bootstrap1}
Let $G = (V,E)$ be a graph and $\theta \in \mathbb{N}$ a threshold.
For any initial configuration $\omega_0 \in \{0,1\}^V$, define a sequence $\omega_i$ for $i \ge 1$ by the recursion
$$
\omega_{j+1}(v)=
\begin{cases}
1& \text{if $\omega_j(v)=1$ or $\sum_{(v,w) \in E}\omega_j(w) \geq
\threshold$}\\
0 &\text{else}
\end{cases}
$$
and let $\omega_\infty = \lim_i \omega_i$. This limit is defined pointwise as $(\omega_i(v))_i$ is increasing for each $v$.
Let $S_0 = \omega_0^{-1}(1)$.

We think of bootstrap percolation as a growing set of {\em infected} or {\em active} vertices which starts with only the vertices in $S_0$ active.
Once a vertex is active, it stays active, and new vertices become active once at least $\theta$ of their neighbors are active.
The main goal is to determine under what conditions the entire graph eventually becomes active; that is, if $\omega_\infty(v) = 1$ for all $v$.
In this case, we say that percolation has occurred, or that $S_0$ {\em spans} $G$.

The initial set $S_0 $ of active vertices can be deterministic or random.
See \cite{pete} for some results on the minimal size of $S_0$ required for percolation in the deterministic case.
In this paper, we let each vertex be active at time 0 independently with probability $p$.
Thus, the bootstrap percolation process becomes a random variable.
We are interested in the probability that percolation occurs.
In Figure \ref{fig:percgraphs}, we plot $\mathbb{P}(\textup{percolation})$ vs $p$ for the graph $[n]^2$ with Euclidean nearest neighbors and threshold $\theta=2$.
As $p$ increases, there is a relatively sharp transition from a low probability of percolation to a high probability.
As we increase $n$, the transition becomes sharper.

\begin{figure}[htd]
\label{fig:percgraphs}
	\centering
\begin{tikzpicture}[scale=3]
\node at (.32,-.1) {0.32};
\node at (.5,1.1) {$n=5$};
%\node[rotate=90] at (-.1,.5) {$\mathbb{P}(\textup{percolation})$};
\draw[very thick] (0,0) -- (1,0) -- (1,1) -- (0,1) -- cycle;
\draw[dotted] (.32,0) -- (.32,1);
\draw[dotted] (0,.5) -- (1,.5);
  \draw[thick] (0,0) -- (0.1,0.0108) -- (0.15,0.0514) -- (0.2,0.1443) -- (0.23,0.2339) -- (0.27,0.3502) -- (0.3,0.4398) -- (0.32,0.4989) -- (0.34,0.5542) -- (0.36,0.6021) -- (0.38,0.659) -- (0.4,0.7126) -- (0.435,0.7841) -- (0.47,0.8411) -- (0.5,0.8788) -- (0.55,0.928) -- (0.6,0.9638) -- (0.7,0.9912) -- (0.8,0.9986) -- (1,1);
\end{tikzpicture}
\hfill
\begin{tikzpicture}[scale=3]
\node at (.195,-.1) {0.19};
\node at (.5,1.1) {$n=10$};
%\node[rotate=90] at (-.1,.5) {$\mathbb{P}(\textup{percolation})$};
\draw[very thick] (0,0) -- (1,0) -- (1,1) -- (0,1) -- cycle;
\draw[dotted] (.195,0) -- (.195,1);
\draw[dotted] (0,.5) -- (1,.5);
  \draw[thick] (0,0) -- (.025,0) -- (.05,.0005) -- (.075,.0049) -- (0.1,0.0333) -- (0.11,0.0539) -- (0.12,0.0841) -- (0.13,0.1298) -- (0.14,0.1776) -- (0.15,0.2369) -- (0.16,0.2949) -- (0.17,0.3546) -- (0.18,0.4124) -- (0.19,0.4674) -- (0.2,0.5277) -- (0.22,0.6441) -- (0.24,0.7197) -- (0.26,0.7911) -- (0.28,0.8466) -- (0.3,0.8852) -- (0.333,0.9259) -- (0.366,0.9575) -- (0.4,0.9762) -- (0.5,0.997) -- (0.6,0.9995) -- (0.7,1.0) -- (0.8,1.0) -- (0.9,1.0) -- (1,1);
\end{tikzpicture}
\hfill
\begin{tikzpicture}[scale=3]
\node at (.145,-.1) {0.14};
\node at (.5,1.1) {$n=15$};
%\node[rotate=90] at (-.1,.5) {$\mathbb{P}(\textup{percolation})$};
\draw[very thick] (0,0) -- (1,0) -- (1,1) -- (0,1) -- cycle;
\draw[dotted] (.145,0) -- (.145,1);
\draw[dotted] (0,.5) -- (1,.5);
  \draw[thick] (0,0) -- (0.025,0) -- (.05,.0005) -- (.075,.0156) -- (0.1,0.1105) -- (0.11,0.1849) -- (0.12,0.2734) -- (0.13,0.3628) -- (0.14,0.4638) -- (0.15,0.5466) -- (0.16,0.6424) -- (0.17,0.7048) -- (0.18,0.7521) -- (0.19,0.8045) -- (0.2,0.8329) -- (0.23,0.9148) -- (0.26,0.9532) -- (0.3,0.9819) -- (0.4,0.9982) -- (0.5,0.9999) -- (0.7,1.0) -- (1,1);
\end{tikzpicture}
\hfill
\begin{tikzpicture}[scale=3]
\node at (.117,-.1) {0.12};
\node at (.5,1.1) {$n=20$};
%\node[rotate=90] at (-.1,.5) {$\mathbb{P}(\textup{percolation})$};
\draw[very thick] (0,0) -- (1,0) -- (1,1) -- (0,1) -- cycle;
\draw[dotted] (.117,0) -- (.117,1);
\draw[dotted] (0,.5) -- (1,.5);
  \draw[thick] (0,0) --   (0.02,0.0) -- (0.04,0.0) -- (0.06,0.0043) -- (0.08,0.0654) -- (0.1,0.2716) -- (.11,.4088) -- (.12,.5414) -- (.13,.6499) -- (0.14,0.7333) -- (0.15,0.8015) -- (0.16,0.8507) -- (0.17,0.8851) -- (0.18,0.9179) -- (0.19,0.9346) -- (0.2,0.9527) -- (.23,.9765) -- (.26,.9893) -- (0.3,0.9968) -- (0.5,1.0)       -- (1,1);
\end{tikzpicture}
\caption{Plots of $\mathbb{P}(\textup{percolation})$ vs $p$ for nearest neighbor $[n]^2$, for $n = 5, 10, 15, 20$. Critical probabilities are indicated.}
\end{figure}

To pin down this transition, we define the {\em critical probability} $p_c$ to be the $p$ at which $\mathbb{P}(\textup{percolation}) = \frac{1}{2}$.
(Since the transition window narrows as $n$ increases, we could choose any fixed $c \in (0,1)$ in the definition without changing the theory.)
We consider a family of graphs $G_n$ and wish to find the dependence of $p_c$ on $n$.
For example, in the example in Figure \ref{fig:percgraphs}, it turns out that $p_c$ scales as $\frac{1}{\log n}$.

For the graphs we consider, it turns out that the critical probability is essentially $n^{a}$ for some $a < 0$ in the following sense.
Let $p = n^b$.
If $b < a$, then $\mathbb{P}(\textup{percolation}) \to 0$ as $n \to \infty$, while if $b > a$, then $\mathbb{P}(\textup{percolation}) \to 1$.
In certain cases, we are able to look within the {\em scaling window} and determine $f(c) = \mathbb{P}(\textup{percolation})$, when $p = cn^a$.

We study bootstrap percolation on the {\em Hamming torus} $G = ([n]^d,E)$, where $x$ and $y$ are adjacent if they differ in exactly one coordinate.
Here $[n] = \{1, \ldots, n\}$.
In Figure \ref{htperc} we see an example of an initial percolating set when $\threshold = 2$ on the two-dimensional Hamming torus.
\begin{figure}[htd]
	\centering
\begin{tikzpicture}
\def\scaledist{.6}
\def\scalesize{.8}
\draw(0*\scaledist,0*\scaledist) circle (4*\scalesize pt) (1*\scaledist,0*\scaledist) circle (4*\scalesize pt) (2*\scaledist,0*\scaledist) circle (4*\scalesize pt) (3*\scaledist,0*\scaledist) circle (4*\scalesize pt) (4*\scaledist,0*\scaledist) circle (4*\scalesize pt) (0*\scaledist,1*\scaledist) circle (4*\scalesize pt) (2*\scaledist,1*\scaledist) circle (4*\scalesize pt) (3*\scaledist,1*\scaledist) circle (4*\scalesize pt) (4*\scaledist,1*\scaledist) circle (4*\scalesize pt) (0*\scaledist,2*\scaledist) circle (4*\scalesize pt) (1*\scaledist,2*\scaledist) circle (4*\scalesize pt) (2*\scaledist,2*\scaledist) circle (4*\scalesize pt) (3*\scaledist,2*\scaledist) circle (4*\scalesize pt) (4*\scaledist,2*\scaledist) circle (4*\scalesize pt) (0*\scaledist,3*\scaledist) circle (4*\scalesize pt) (1*\scaledist,3*\scaledist) circle (4*\scalesize pt) (2*\scaledist,3*\scaledist) circle (4*\scalesize pt) (3*\scaledist,3*\scaledist) circle (4*\scalesize pt) (0*\scaledist,4*\scaledist) circle (4*\scalesize pt) (1*\scaledist,4*\scaledist) circle (4*\scalesize pt) (2*\scaledist,4*\scaledist) circle (4*\scalesize pt) (3*\scaledist,4*\scaledist) circle (4*\scalesize pt) (4*\scaledist,4*\scaledist) circle (4*\scalesize pt) (6*\scaledist,0*\scaledist) circle (4*\scalesize pt) (7*\scaledist,0*\scaledist) circle (4*\scalesize pt) (8*\scaledist,0*\scaledist) circle (4*\scalesize pt) (9*\scaledist,0*\scaledist) circle (4*\scalesize pt) (10*\scaledist,0*\scaledist) circle (4*\scalesize pt) (6*\scaledist,1*\scaledist) circle (4*\scalesize pt) (8*\scaledist,1*\scaledist) circle (4*\scalesize pt) (9*\scaledist,1*\scaledist) circle (4*\scalesize pt) (6*\scaledist,2*\scaledist) circle (4*\scalesize pt) (7*\scaledist,2*\scaledist) circle (4*\scalesize pt) (8*\scaledist,2*\scaledist) circle (4*\scalesize pt) (9*\scaledist,2*\scaledist) circle (4*\scalesize pt) (10*\scaledist,2*\scaledist) circle (4*\scalesize pt) (6*\scaledist,3*\scaledist) circle (4*\scalesize pt) (8*\scaledist,3*\scaledist) circle (4*\scalesize pt) (9*\scaledist,3*\scaledist) circle (4*\scalesize pt) (6*\scaledist,4*\scaledist) circle (4*\scalesize pt) (7*\scaledist,4*\scaledist) circle (4*\scalesize pt) (8*\scaledist,4*\scaledist) circle (4*\scalesize pt) (9*\scaledist,4*\scaledist) circle (4*\scalesize pt) (10*\scaledist,4*\scaledist) circle (4*\scalesize pt) (12*\scaledist,0*\scaledist) circle (4*\scalesize pt) (14*\scaledist,0*\scaledist) circle (4*\scalesize pt) (15*\scaledist,0*\scaledist) circle (4*\scalesize pt) (12*\scaledist,2*\scaledist) circle (4*\scalesize pt) (14*\scaledist,2*\scaledist) circle (4*\scalesize pt) (15*\scaledist,2*\scaledist) circle (4*\scalesize pt) (12*\scaledist,4*\scaledist) circle (4*\scalesize pt) (14*\scaledist,4*\scaledist) circle (4*\scalesize pt) (15*\scaledist,4*\scaledist) circle (4*\scalesize pt) ;
\draw[fill=black](1*\scaledist,1*\scaledist) circle (4*\scalesize pt) (4*\scaledist,3*\scaledist) circle (4*\scalesize pt) (7*\scaledist,1*\scaledist) circle (4*\scalesize pt) (10*\scaledist,3*\scaledist) circle (4*\scalesize pt) (10*\scaledist,1*\scaledist) circle (4*\scalesize pt) (7*\scaledist,3*\scaledist) circle (4*\scalesize pt) (13*\scaledist,1*\scaledist) circle (4*\scalesize pt) (16*\scaledist,3*\scaledist) circle (4*\scalesize pt) (16*\scaledist,1*\scaledist) circle (4*\scalesize pt) (13*\scaledist,3*\scaledist) circle (4*\scalesize pt) (12*\scaledist,3*\scaledist) circle (4*\scalesize pt) (14*\scaledist,3*\scaledist) circle (4*\scalesize pt) (15*\scaledist,3*\scaledist) circle (4*\scalesize pt) (12*\scaledist,1*\scaledist) circle (4*\scalesize pt) (14*\scaledist,1*\scaledist) circle (4*\scalesize pt) (15*\scaledist,1*\scaledist) circle (4*\scalesize pt) (13*\scaledist,4*\scaledist) circle (4*\scalesize pt) (16*\scaledist,4*\scaledist) circle (4*\scalesize pt) (13*\scaledist,2*\scaledist) circle (4*\scalesize pt) (16*\scaledist,2*\scaledist) circle (4*\scalesize pt) (13*\scaledist,0*\scaledist) circle (4*\scalesize pt) (16*\scaledist,0*\scaledist) circle (4*\scalesize pt) (19*\scaledist,1*\scaledist) circle (4*\scalesize pt) (22*\scaledist,3*\scaledist) circle (4*\scalesize pt) (22*\scaledist,1*\scaledist) circle (4*\scalesize pt) (19*\scaledist,3*\scaledist) circle (4*\scalesize pt) (18*\scaledist,3*\scaledist) circle (4*\scalesize pt) (20*\scaledist,3*\scaledist) circle (4*\scalesize pt) (21*\scaledist,3*\scaledist) circle (4*\scalesize pt) (18*\scaledist,1*\scaledist) circle (4*\scalesize pt) (20*\scaledist,1*\scaledist) circle (4*\scalesize pt) (21*\scaledist,1*\scaledist) circle (4*\scalesize pt) (19*\scaledist,4*\scaledist) circle (4*\scalesize pt) (22*\scaledist,4*\scaledist) circle (4*\scalesize pt) (19*\scaledist,2*\scaledist) circle (4*\scalesize pt) (22*\scaledist,2*\scaledist) circle (4*\scalesize pt) (19*\scaledist,0*\scaledist) circle (4*\scalesize pt) (22*\scaledist,0*\scaledist) circle (4*\scalesize pt) (18*\scaledist,4*\scaledist) circle (4*\scalesize pt) (20*\scaledist,4*\scaledist) circle (4*\scalesize pt) (21*\scaledist,4*\scaledist) circle (4*\scalesize pt) (18*\scaledist,2*\scaledist) circle (4*\scalesize pt) (20*\scaledist,2*\scaledist) circle (4*\scalesize pt) (21*\scaledist,2*\scaledist) circle (4*\scalesize pt) (18*\scaledist,0*\scaledist) circle (4*\scalesize pt) (20*\scaledist,0*\scaledist) circle (4*\scalesize pt) (21*\scaledist,0*\scaledist) circle (4*\scalesize pt) ;
\draw (5*\scaledist,-1*\scaledist) -- (5*\scaledist,5*\scaledist);
\draw (11*\scaledist,-1*\scaledist) -- (11*\scaledist,5*\scaledist);
\draw (17*\scaledist,-1*\scaledist) -- (17*\scaledist,5*\scaledist);
\end{tikzpicture}
\caption{The bootstrap percolation process with threshold $\threshold = 2$ on the Hamming torus with $n=5$, $d=2$. Nodes are adjacent iff they share an $x$ or $y$ coordinate. This example takes four steps to percolate.}
\label{htperc}
\end{figure}

\subsection{Background}
Bootstrap percolation was introduced in 1979 by Chalupa, Leath and Reich \cite{bethe} as a model of nucleation and metastability in physical processes such as crack formations, clustering, and magnetic spin alignment.
For more applications and background see surveys by Adler and Levi \cite{brazil} and Holroyd~\cite{holroyd-survey}.

The first results in this area were by van Enter~\cite{vanenter} and Schonmann~\cite{schonmann}, who proved that for the lattice $\mathbb{Z}^d$, the critical probability $p_c$ is either 0 or 1 according to whether $\threshold \le d$ or $\threshold > d$. 
For a large lattice cube $[n]^d\subset \mathbb{Z}^d$ (where each point is connected to the nearest $2d$ points), Aizenman and Lebowitz \cite{aizenman} proved that $p_c$ behaves as $(\frac{1}{\log n})^{d-1}$ when $\threshold=2$.
Later Cerf and Cirillo~\cite{cerfcirillo} and Cerf and Manzo~\cite{cerfmanzo} established the scaling $p_c \approx (\log_{\threshold-1} n)^{-d+\threshold-1}$ for $3\le \theta\le d$.
Here $\log_{\threshold-1}$ denotes the $(\theta-1)$'st iteration of the logarithm. 

The Hamming torus is interesting because of computer simulations showing that the percolation on $[n]^d$ tends to proceed along straight lines.
By changing the distance to the Hamming metric, we can investigate this behavior.

\subsection{Results}
All our results are for the Hamming torus described in \ref{section:bootstrap1}. 
In addition to finding the critical probability for the entire graph to percolate, we consider the event that an $i$-dimensional subgraph percolates.
We find an expression for the critical probability of this event for $1 \le i \le d$.
\begin{itemize}
\item For $d=2$, we find the critical probability exponent for all $\theta$ and describe the behavior within the scaling window as $n \to \infty$.
For $d=\theta = 3$, we again find the critical probability and describe the limiting behavior within the scaling window.
These results are powered by Stein's method \cite{poissonbook}, a method for dealing with almost independent events.
\item For all $d$ and all $i \ge 2$, we show that the critical probability for an $i$-dimensional subgraph to percolate is $p_c = n^{-1-\frac{2}{\theta} + \Theta(\theta^{-\frac{3}{2}})}$.
We prove this by constructing critical events which are necessary (respectively sufficient) for percolation and which are easier to analyze than the percolation event.
We show that when $p >> p_c$, the sufficient event happens with probability going to 1, and with $p << p_c$, the necessary event happens with probability going to 0.
\item In particular, we show that the critical probability for the entire graph to percolate is, as above, $p_c = n^{-1-\frac{2}{\theta} + \Theta(\theta^{-\frac{3}{2}})}$.
\end{itemize}

\subsection{Comments}
Although our results are stated asymptotically in $n$ and for large $\theta$, the proofs in fact give results for large finite graphs.
However, computing the constants involved is arduous. 

It is interesting that the critical probabilities are all approximately $n^{-1-\frac{2}{\theta}}$ for $2 \le i \le d$.
It turns out that for $i=1$, the critical probability is $n^{-1-\frac{d}{\theta}}$, a qualitatively different behavior.

For $d = 3$ we get the same upper and lower bound for $p_c$ for $\theta \le 7$ as well as $\theta = 9, 11$, and therefore can determine the exact critical exponent.
This raises the question of whether our proof technique can be improved to bring the bounds closer together for other values of $\theta$.

\section{Combinatorial Optimization and Sums of Squares}
\label{section:cosos}
Chapters \ref{chap:kicover} and \ref{chap:cube} study the application of sums of squares of polynomials to combinatorial optimization. 
In this section, we give a description of the general area of combinatorial optimization and of polynomial sums of squares in particular.
We introduce many of the concepts which will be used later.

\subsection{Combinatorial Optimization}
\label{section:copt}
{\em Combinatorial optimization} is the study of optimizing a function over a finite set. 
By interpolation, all such functions are polynomials in the decision variables.
Applications are common in computer science, mathematics, and operations research.
For example, the goal of the {\em traveling salesman problem} is to find a minimum-cost tour among a set of cities.
The goal of the {\em shortest path problem} is to find a shortest-distance path between two nodes in a graph, and the goal of the {\em assignment problem} is to assign workers to jobs while minimizing the total wages paid. 

In each of the above problems, we minimize a linear function over a finite set.
For instance, in the traveling salesman problem (TSP), we model the problem as a complete graph $G=([n],{ {[n]} \choose 2})$.
For each $e \in E$, a cost $c_e$ is given.
The vertices represent cities, with specified costs to travel between them.
We want to find the minimum of $f(T) = \sum_{e \in E} c_ex_e$ over all tours $T$.
Here, a tour is represented by a 0/1 vector $x \in \mathbb{R}^{n \choose 2}$, with $x_e = 1$ if and only if the edge $e$ is part of $T$.

A common approach is to rewrite this as an {\em integer linear program} by replacing the constraints $x_e \in \{0,1\}$ by $x_e \in \mathbb{Z}$, $0 \le x_e \le 1$, and encoding the fact that $T$ is a tour using other linear constraints.
But since we optimize a linear function, the optimum is unchanged if we instead optimize over the {\em convex hull} $\textup{TSP}(n)$ of all tours.
The set $\textup{TSP}(n) \subset [0,1]^{n \choose 2}$ is a polytope whose vertices are the vectors coming from tours.
This is a natural object to study without referring to a specific set $(c_e)$ of costs, since changing the costs is equivalent to optimizing in a different direction over $\textup{TSP}(n)$.

To explain this geometric approach in general, consider a problem where we optimize a linear function over some feasible collection $\mathcal{C}$ of subsets of a fixed set $X$.
For instance, in the TSP we let $\mathcal{C}$ be the collection of all tours; here $X$ is the set of edges.
In the shortest-path problem we consider $\mathcal{C}$ to be the collection of all paths from a fixed $x \to y$; again $X$ is the set of edges.
A non-graph example is the knapsack problem, where $\mathcal{C}$ is the set of subsets of $X = \{1, \ldots, n\}$ satisfying a capacity constraint.
In general, we will assume that $X = \{1, \ldots, n\}$ for some $n$; this can always be accomplished by enumerating $X$.
For each $C \in \mathcal{C}$, define its characteristic vector $\chi_C \in \{0,1\}^n$, where for $1 \le i \le n$, $(\chi_C)_i = 1$ if and only if $i \in C$.
Then define the polytope $P(\mathcal{C}) = \conv \{\chi_C: C \in \mathcal{C}\}$.
If we can optimize any linear function in polynomial time over $P(\mathcal{C})$, we can optimize the same linear function over $\mathcal{C}$ in polynomial time.

Of course, many combinatorial optimization problems often end up being NP-complete or harder. 
That is, we are unlikely to ever find efficient algorithms to solve them exactly.
In some cases where the abstract mathematical problem does have an efficient algorithm, real-world constraints can make it intractable. 
For instance, when assigning medical students to residencies, the constraint that married pairs of students live in the same city makes the problem NP-complete.
Therefore, much research has focused on developing methods to solve these problems approximately. 
Using various methods, we can construct a relaxation $P'(\mathcal{C})$ to $ P(\mathcal{C})$ and try to show that the gap between them is not very large.
In the next section, we describe one such method based on sums of squares of polynomials.

\subsection{Sums of Squares and the Theta Body}
\label{section:introtheta}
Consider for the moment unconstrained polynomial optimization problems on $\RR^n$. 
That  is, we are given a polynomial $f \in \RR[x_1, \ldots, x_n]$, and must find the global minimum value $f_{\min}$. 
It turns out that optimization is closely related to checking nonnegativity.
If we can find the global minimum of a polynomial $f$, we can certainly check if $f$ is nonnegative everywhere by checking if its minimum $f_{\min} \ge 0$.
Conversely, if we can check whether polynomials are nonnegative, we can compute $f_{\min}$: observe that $f_{\min} = \max \{r: f(x) - r \ge 0\}$. 
We can solve the latter problem by sampling different $r$ (e.g. with binary search) and for each $r$ checking whether $f - r$ is nonnegative.

Checking arbitrary polynomials for nonnegativity is NP-hard, so we seek an approximation.
Note that if we can write $f(x)$ as a sum of squares (of polynomials), then it is certainly nonnegative. 
Therefore, we can define the relaxation $f_{\textup{sos}} = \max \{r: f(x) - r \textup{ is a sum of squares}\}$.
We have that $f_{\min} \ge f_{\textup{sos}}$, so this is a lower bound on the minimum. 
This idea is discussed at more length in \cite{sostools} and \cite{lasserre}. 

So far, this only makes sense for polynomials on $\mathbb{R}^n$.
We will define a notion of sums of squares that is applicable to combinatorial optimization problems.
This definition originated with Lov\'asz \cite{lovasz} and was used to produce an approximation to the {\em stable set problem}.
It was generalized by Gouveia, Parrilo, and Thomas \cite{gpt} to give an approximation to the convex hull of any algebraic set.
This idea is also closely related to Lasserre's \cite{lasserre} and Parrilo's \cite{parrilo} \cite{parrilo2} heirarchies for polynomial optimization.

As in Section \ref{section:copt}, consider a collection $\mathcal{C}$ of subsets of $\{1, \ldots, n\}$. 
Let $\mathcal{V} = \{\chi_C: C \in \mathcal{C}\}$.
Since $\mathcal{V}$ is a finite set, it is an {\em algebraic variety}.
That is, it is the set of solutions of a finite list of polynomials.
The {\em ideal} $I$ of $\mathcal{V}$ is defined to be the set of all polynomials vanishing on $\mathcal{V}$.
We can define an equivalence relation on polynomials, denoted $f \equiv g \mod I$, if and only if $f - g \in I$.
It turns out that $f \equiv g \mod I$ if and only if $f(x) = g(x)$ for each $x \in \mathcal{V}$.
For a polynomial $f$ and an integer $k$, we say $f$ is {\em $k$-sos mod $I$} if we can write $f \equiv \sum_i g_i^2 \mod I$ for some polynomials $g_i$ with degree at most $k$.
Now define the $k$th {\em theta body} of $I$, $\textup{TH}_k(I)$, to be the intersection of all affine linear functions $f$ which are $k$-sos mod $I$. 
This defines a relaxation of the convex hull of $\mathcal{V}$: $\conv(\mathcal{V}) \subseteq \textup{TH}_k(I)$ for each $k$, with the approximation improving as $k$ increases.
In our case, $\mathcal{V} \subseteq \{0,1\}^n$, so it turns out that $\textup{TH}_n(I) =  \conv(\mathcal{V})$.
We can optimize over $\textup{TH}_k(I)$ to fixed precision, for fixed $k$,  in time polynomial in $n$.
This is done using {\em semidefinite programming}, and provides an efficient relaxation to $P(\mathcal{C}) = \conv(\mathcal{V})$ for small $k$.

As an example of the theta body heirarchy, we describe the first theta body of the stable set problem.
Historically, this was the first example where theta bodies were used, and where the general heirarchy was abstracted from.
Given a graph $G=(V,E)$, a subset $C$ of $V$ is {\em stable} if for all $i,j \in C$, $(ij) \notin E$. 
Let $n = |V|$.
As in Section \ref{section:copt}, we will consider the set $\mathcal{V} \subset \{0,1\}^n$ of characteristic vectors of stable sets in $G$.
Our goal is to describe the convex hull $\conv(\mathcal{V})$, denoted $\textup{STAB}(G)$.
We can check that the ideal of $\mathcal{V}$ is 
$$I = \langle x_i^2 - x_i \, \forall \le i \le n\, ;\,  x_ix_j \, \forall (ij) \in E \rangle.$$
To describe the first theta body $\textup{TH}_1(I)$, denoted $\textup{TH}(G)$ in this case, we must find all linear functions which are sums of squares of linear polynomials mod $I$.
It turns out that $\textup{TH}(G)$ has a semidefinite description first discovered by Lov\'asz \cite{lovasz}.
We reproduce it here; see Chapter 9 of \cite{gls} for the derivation: $x \in \textup{TH}(G)$ if and only if there exists $M \in \mathbb{R}^{(n + 1) \times (n + 1)}$
such that $M \succeq 0$ and the following linear conditions hold:
\begin{enumerate}
\item For $1 \le i \le n$, $M_{0i} = M_{ii} = x_i$,
\item For each $ij \in E$, $M_{ij} = 0$,
\item $M_{00} = 1$.
\end{enumerate}

The class of graphs for which $\textup{TH}(G) = \textup{STAB}(G)$ is known to be exactly the {\em perfect graphs}.
A graph is $G$ defined to be perfect if the chromatic number equals the clique number for each induced subgraph of $G$.
Equivalently, $G$ is perfect if $G$ contains no induced odd cycle or the complement of an odd cycle; see Figure \ref{stabtheta}.

\begin{figure}[htd]
	\centering
\begin{tikzpicture}
  [scale=1.2,auto=left,every node/.style={circle,fill=black,inner
sep=0pt, minimum width=6pt}]  \node (0) at
(1.00000000000000,0.000000000000000) {};
  \node (1) at (0.309016994374947,0.951056516295154) {};
  \node (2) at (-0.809016994374947,0.587785252292473) {};
  \node (3) at (-0.809016994374947,-0.587785252292473) {};
  \node (4) at (0.309016994374947,-0.951056516295154) {};


  \draw (0) -- (1);
  \draw (0) -- (4);
  \draw (1) -- (2);
  \draw (2) -- (3);
  \draw (3) -- (4);

\end{tikzpicture}
\hspace{1cm}
\begin{tikzpicture}
  [scale=.8,auto=left,every node/.style={circle,fill=black,inner
sep=0pt, minimum width=6pt}]  \node (1) at
(-1.00000000000000,1.00000000000000) {};
  \node (2) at (-1.00000000000000,0.000000000000000) {};
  \node (3) at (-1.00000000000000,-1.00000000000000) {};
  \node (4) at (1.00000000000000,-1.50000000000000) {};
  \node (5) at (1.00000000000000,0.000000000000000) {};
  \node (6) at (1.00000000000000,1.50000000000000) {};


  \draw (1) -- (4);
  \draw (1) -- (5);
  \draw (1) -- (6);
  \draw (2) -- (4);
  \draw (2) -- (5);
  \draw (2) -- (6);
  \draw (3) -- (4);
  \draw (3) -- (5);
  \draw (3) -- (6);

\end{tikzpicture} 
\hfill
\caption{(Left) the odd cycle $C_5$. (Right) a perfect graph.}
\label{stabtheta}
\end{figure}

There is an older polyhedral relaxation to $\textup{STAB}(G)$ known as $\textup{QSTAB}(G)$.
This is the polytope in $[0,1]^n$ cut out by the nonnegativities $x_i \ge 0$ and the {\em clique inequalities} $\sum_{i \in K} x_i \le 1$ for each clique $K$ in $G$.
Since $f = 1 - \sum_{i \in K} x_i$ is idempotent mod $I$, that is, $f^2 \equiv f \mod I$, it is visibly a sum of squares.
Therefore the clique inequalities are valid on $\textup{TH}(G)$, and $\textup{STAB}(G) \subseteq \textup{TH}(G) \subseteq \textup{QSTAB}(G)$.


\section{A Semidefinite Approach to the $K_{\lowercase{i}}$-Cover Problem}
Chapter \ref{chap:kicover} is taken from a paper coauthored with Jo\~ao Gouveia and submitted to \emph{Operations Research Letters}. %FIXME
It is an application of theta bodies to the $K_i$-cover problem.

\subsection{Problem Description}

The {\em $K_i$-cover problem} is a generalization of the stable set problem discussed in Section \ref{section:cosos}.
A graph $G = (V,E)$ is given. 
For any $k$, a $k$-clique in $G$, denoted $K_i$, is a collection of $k$ nodes, each pair of which is connected by an edge in $E$.
We define a covering relation where an $i$-clique $H_1$ is covered by an $(i-1)$-clique $H_2$ if $H_1 \supseteq H_2$; i.e., if $H_2$ is a subgraph of $H_1$. 
A $K_i$-cover in $G$ is a collection $\mathcal{C}$ of $(i-1)$-cliques in $G$ such that each $i$-clique in $G$ is covered by some element of $\mathcal{C}$. 
The $K_i$-cover problem is to find such a collection $\mathcal{C}$ of smallest size.
In the graph $G$ in Figure \ref{K5}, a $K_4$-cover is given by $\{012,034,023\}$.

\begin{figure}[htd]
	\centering
\begin{tikzpicture}
  [scale=1.4,auto=left,every node/.style={circle,inner sep=0pt, minimum width=6pt}]  
  \node (0) at (1.00000000000000,0.000000000000000) {0};
  \node (1) at (0.309016994374947,0.951056516295154) {1};
  \node (2) at (-0.809016994374947,0.587785252292473) {2};
  \node (3) at (-0.809016994374947,-0.587785252292473) {3};
  \node (4) at (0.309016994374947,-0.951056516295154) {4};


  \draw (0) -- (1);
  \draw (0) -- (2);
  \draw (0) -- (3);
  \draw (0) -- (4);
  \draw (1) -- (2);
  \draw (1) -- (3);
  \draw (1) -- (4);
  \draw (2) -- (3);
  \draw (2) -- (4);
  \draw (3) -- (4);

\end{tikzpicture}
\hspace{1cm}
\begin{tikzpicture}
  [scale=1.4,auto=left,every node/.style={circle,inner sep=0pt, minimum width=6pt}]  
  \node (0) at (1.00000000000000,0.000000000000000) {0};
  \node (1) at (0.309016994374947,0.951056516295154) {1};
  \node (2) at (-0.809016994374947,0.587785252292473) {2};
  \node (3) at (-0.809016994374947,-0.587785252292473) {3};
  \node (4) at (0.309016994374947,-0.951056516295154) {4};


  \draw (0) -- (1);
  \draw (0) -- (2);
  \draw (0) -- (3);
  \draw (0) -- (4);
  \draw (1) -- (2);
  \draw (2) -- (3);
  \draw (3) -- (4);

\end{tikzpicture}
\hfill
	\caption{A graph with 5 copies of $K_4$: 0123,0124,0134,0234,1234; along with an example $K_4$-cover.}
	\label{K5}
\end{figure}

When $i=2$, the $K_i$-cover problem is the \emph{vertex cover problem} - to find the smallest set $\mathcal{C}$ of vertices such that each edge is covered by a vertex in $\mathcal{C}$. 
To make the connection to the stable set problem, note that $\mathcal{C} \subseteq V$ is a vertex cover if and only if $V \setminus \mathcal{C}$ is a stable set.
Therefore, the problems are essentially equivalent.
In fact, the polytopes defined by these problems as in section 1.1 are congruent via the transformation $x_j \mapsto 1-x_j$ in each coordinate.
Similarly, a set $\mathcal{C}$ of $K_{i-1}$s is a $K_i$-cover if and only if its complement $\mathcal{C}^c$ is $K_i$-free.

We will need the description of the ideal $I$ of the variety of $K_i$-free sets.
We merely state it here; for the derivation see Chapter \ref{chap:kicover}.
Let $X$ be the collection of $K_{i-1}$s in $G$ and $Y$ the collection of $K_i$s in $G$.
$$I = \langle x_H^2 - x_H\, \forall \le H \in X\, ;\,  \prod_{H \subseteq H'} x_H\, \forall H' \in Y \rangle.$$
To understand this, recall that we have a variable $x_H$ for each $K_{i-1}$ $H$ in $G$.
The functions that generate $I$ come in two forms.
The type $x_H^2 - x_H = 0$ enforces the constraint that $x_H \in \{0,1\}$, i.e., that $x$ is a characteristic vector.
The type $\prod_{H \subseteq H'} x_H= 0$ ensures that $x$ actually comes from a $K_i$-free set.

\subsection{Background}

The stable set and vertex cover problems have been studied in many contexts. 
The $K_i$-cover generalization was first studied in Conforti et al \cite{conforti}, wherein the associated polytope $P_i(G)$ was considered and several families of facets identified. 
As in Section 1.1, $P_i(G) \subseteq \mathbb{R}^N$ is the convex hull of characteristic vectors of $K_i$-covers, where $N$ is the number of $K_{i-1}$s in $G$. 
Conforti et al provided polynomial-time {\em separation oracles} for many of these families of facets. 
A separation oracle for a family $\mathcal{F}$ of facets is a decision procedure which takes a point $x$ and decides whether $x$ satisfies each facet $F \in \mathcal{F}$, or whether $x$ lies outside some facet $F \in \mathcal{F}$.
Since a typical family $\mathcal{F}$ will contain exponentially many elements, it is not possible in general to enumerate the $F \in \mathcal{F}$ and check them one by one, making such an oracle a nontrivial result.

Conforti et al left open the existence of oracles for several families of facets, including the family associated with the {\em $K_i$-$p$-holes}. 
A graph $H$ is a $K_i$-$p$-hole if it contains $p$ copies of $K_i$ arranged in a cycle, with neighboring $K_i$ sharing a common $K_{i-1}$. 
This does not determine $H$ up to isomorphism; see Figure \ref{chap1:9holeintro} for three nonisomorpic $K_3$-9-holes.
To understand the facet inequality associated to a $K_i$-$p$-hole, consider the graphs in Figure 2. 
To construct a $K_3$-cover of minimum size, we need to pick an edge from each $K_3$. 
We can pick four edges to eliminate eight $K_3$s, but we still need a fifth to pick up the last $K_3$. 
Therefore, $\sum_{e \subseteq H} x_e \ge 5$ is valid on the polytope $P_3(G)$ for any graph $G$ containing $H$ as a subgraph. 
The inequality for general $K_i$-$p$-holes is derived from a similar argument, and is given by $\sum_{e \subseteq H} x_e \ge \lceil \frac{p}{2} \rceil$.
It defines a facet of $P_i(G)$ for $i \ge 3$ and odd $p$.

\begin{figure}[htd]
\begin{tikzpicture}
  [scale=1.8,every node/.style={circle,fill=black,inner
sep=0pt, minimum width=6pt}]  \node (0) at
(1.00000000000000,0.000000000000000) {};
  \node (1) at (0.766044443118978,0.642787609686539) {};
  \node (2) at (0.173648177666930,0.984807753012208) {};
  \node (3) at (-0.500000000000000,0.866025403784439) {};
  \node (4) at (-0.939692620785908,0.342020143325669) {};
  \node (5) at (-0.939692620785908,-0.342020143325669) {};
  \node (6) at (-0.500000000000000,-0.866025403784439) {};
  \node (7) at (0.173648177666930,-0.984807753012208) {};
  \node (8) at (0.766044443118978,-0.642787609686540) {};


  \draw (0) -- (1);
  \draw (0) -- (2);
  \draw (0) -- (7);
  \draw (0) -- (8);
  \draw (1) -- (2);
  \draw (1) -- (3);
  \draw (1) -- (8);
  \draw (2) -- (3);
  \draw (2) -- (4);
  \draw (3) -- (4);
  \draw (3) -- (5);
  \draw (4) -- (5);
  \draw (4) -- (6);
  \draw (5) -- (6);
  \draw (5) -- (7);
  \draw (6) -- (7);
  \draw (6) -- (8);
  \draw (7) -- (8);

\end{tikzpicture}\hfill
\begin{tikzpicture}
  [scale=.9,every node/.style={circle,fill=black,inner
sep=0pt, minimum width=6pt}]  \node (0) at (1,0) {};
  \node (1) at (-0.150000000000000,1.20000000000000) {};
  \node (2) at (-0.600000000000000,0.600000000000000) {};
  \node (3) at (-0.600000000000000,-0.600000000000000) {};
  \node (4) at (-0.150000000000000,-1.20000000000000) {};
  \node (5) at (2,0) {};
  \node (6) at (0,2) {};
  \node (7) at (-2,0) {};
  \node (8) at (0,-2) {};


  \draw (0) -- (1);
  \draw (0) -- (4);
  \draw (0) -- (5);
  \draw (1) -- (2);
  \draw (1) -- (5);
  \draw (1) -- (6);
  \draw (1) -- (7);
  \draw (2) -- (3);
  \draw (2) -- (7);
  \draw (3) -- (4);
  \draw (3) -- (7);
  \draw (4) -- (5);
  \draw (4) -- (7);
  \draw (4) -- (8);
  \draw (5) -- (6);
  \draw (5) -- (8);
  \draw (6) -- (7);
  \draw (7) -- (8);

\end{tikzpicture}\hfill
\begin{tikzpicture}
  [scale=1.8,every node/.style={circle,fill=black,inner
sep=0pt, minimum width=6pt}]  \node (0) at
(1.00000000000000,0.000000000000000) {};
  \node (1) at (0.766044443118978,0.642787609686539) {};
  \node (2) at (0.173648177666930,0.984807753012208) {};
  \node (3) at (-0.500000000000000,0.866025403784439) {};
  \node (4) at (-0.939692620785908,0.342020143325669) {};
  \node (5) at (-0.939692620785908,-0.342020143325669) {};
  \node (6) at (-0.500000000000000,-0.866025403784439) {};
  \node (7) at (0.173648177666930,-0.984807753012208) {};
  \node (8) at (0.766044443118978,-0.642787609686540) {};
  \node (9) at (0.000000000000000,0.000000000000000) {};


  \draw (0) -- (1);
  \draw (0) -- (8);
  \draw (0) -- (9);
  \draw (1) -- (2);
  \draw (1) -- (9);
  \draw (2) -- (3);
  \draw (2) -- (9);
  \draw (3) -- (4);
  \draw (3) -- (9);
  \draw (4) -- (5);
  \draw (4) -- (9);
  \draw (5) -- (6);
  \draw (5) -- (9);
  \draw (6) -- (7);
  \draw (6) -- (9);
  \draw (7) -- (8);
  \draw (7) -- (9);
  \draw (8) -- (9);

\end{tikzpicture}
	\caption{Three non-isomorphic $K_3$-9-holes.}
	\label{chap1:9holeintro}
\end{figure}

\subsection{Results}
\begin{itemize}
\item Our main result is that the family of facets corresponding to $K_i$-$p$-holes is valid on the theta body $\textup{TH}_{\lceil i/2\rceil }(I)$.
Therefore, for fixed $i$, we have a polynomial-time algorithm to optimize over a relaxation at least as tight as the polyhedron described by this family. 
To show that the $K_i$-$p$-hole facets are valid on $\textup{TH}_{\lceil i/2\rceil}(I)$, we exhibit a set of  polynomials which are {\em idempotent} mod $I$, and whose sum is the facet-defining inequality.
\end{itemize}
We also proved two results about the triangle free problem, the case $i=3$ of the $K_i$-free problem.
\begin{itemize}
\item For the triangle free problem on the complete graph $K_n$, we show that $P_3(K_n) \subsetneq \textup{TH}_{k}(I)$ for $k < n/2$.
That is, it takes at least $n/2$ steps for the theta body heirarchy to converge to the triangle free polytope for $K_n$, and therefore this heirarchy does not give a polynomial-time algorithm for the triangle free problem.
We show this by observing that the cut polytope and triangle free polytope of $K_n$ share a facet, and apply a result of Laurent \cite{moniquestuff} that the theta heirarchy takes at least $n/2$ steps to reach this facet.
\item We show that there is an {\em integrality gap} of $1/2$ for the triangle cover problem's second theta relaxation. 
That is, if we optimize in the all-ones direction in the triangle cover problem, we have 
$$\min \{1 \cdot x: x \in \textup{TH}_2(I) \} \ge \frac{1}{2} \min \{1 \cdot x: x \in P_3(G)\}$$
or all $G$. 
We prove this by applying a result of Krivelevich \cite{krivelevich} on a fractional relaxation of the same problem, and proving that $\textup{TH}_2(I)$ is contained in this fractional relaxation.
\end{itemize}
\subsection{Comments}
In our main result, we consider the theta body $\textup{TH}_{\lceil i/2 \rceil}(I)$. 
The reason for choosing this level of the theta heirarchy is that the generators of the $K_i$-free ideal are polynomials of degree $i$.
Therefore, they can't capture any inequalities on $\textup{TH}_k(I)$ when $2k < i$, so $\textup{TH}_{\lceil i/2 \rceil}(I)$ is the first theta body it makes sense to consider.

We don't fully address the question raised in Conforti et al \cite{conforti} of whether there is a polynomial time separation oracle for the family $\mathcal{F}$ of $K_i$-$p$-hole facets.
We show that these facets are valid on $\textup{TH}_{\lceil i/2\rceil}(I)$, and that we can check membership of $\textup{TH}_{\lceil i/2 \rceil}(I)$ in polynomial time. 
However, this does not give a separation oracle for $\mathcal{F}$.
Indeed, let $Q$ be the body defined as the intersection of all $F \in \mathcal{F}$.
We have $P_i(G) \subseteq \textup{TH}_{\lceil i/2\rceil}(I) \subseteq Q$, so in terms of an approximation to $P_i(G)$, the theta body is tighter, and we can optimize over it in polynomial time (for fixed $i$).
However, this doesn't allow us to optimize over exactly $Q$ in polynomial time.
In fact, for $i=2$, the stable set case, we have a similar phenomenon: $\textup{STAB}(G) \subseteq \textup{TH}(G) \subseteq \textup{QSTAB}(G)$; recall \ref{section:introtheta} for the definitions of these bodies.
In this case it is NP-hard to optimize over either $\textup{STAB}(G)$ or $\textup{QSTAB}(G)$, while $\textup{TH}(G)$ can be optimized over in polynomial time.


Conforti et al \cite{conforti} found additional facets of $P_i(G)$, associated to other subgraphs of $G$, for which no separation oracle is currently known. 
We checked numerically and found that they did not appear to be valid on $\textup{TH}_{\lceil i/2\rceil}(I)$, but they may be valid on higher theta bodies.

\section{Sums of Squares on the Unit Hypercube}
Chapter \ref{chap:cube} is taken from a paper co-authored with Greg Blekherman and Jo\~ao Gouveia, currently being written. %FIXME
It describes a criterion for certain polynomials to be sums of squares mod the ideal of the unit hypercube.

\subsection{Problem Description}
We begin by describing the {\em max cut problem}.
A {\em cut} in a graph $G=(V,E)$ is a partition of $V$ into two sets $A$ and $B$; variously, a cut also refers to the set $C$ of edges between $A$ and $B$.
The max cut problem is to find a cut containing the maximum number of edges.
Alternatively, if a set of weights $(w_{ij})$ is given, it can refer to finding the cut $C$ maximizing $\sum_{ij \in C} w_{ij}$.
For example, in the complete graph $K_n$, max cuts with unit weights are attained by partitioning the vertices into two sets of size $\frac{n}{2}$ if $n$ is even, or sizes $\frac{n-1}{2}$ and $\frac{n+1}{2}$ if $n$ is odd.

As in Section \ref{section:cosos}, we can associate a cut $C$ with its charactistic vector $\chi_C \in \{0,1\}^{n \choose 2}$.
Let $\mathcal{C}$ be the set of all characteristic vectors of cuts.
We let the {\em max cut polytope} be $P(G) = \conv (\mathcal{C})$.
Then the max cut problem becomes $\max \{sum_{ij} w_{ij}x_{ij}: x \in P(G) \}$.
This is called the {\em edge model} of the polyhedral formulation of the max cut problem.
In the case $G = K_n$, the max cuts have size $\lfloor \frac{n^2}{4} \rfloor$, so the function $f(x) = \lfloor \frac{n^2}{4} \rfloor - \sum x_{ij} \ge 0$ on $\mathcal{C}$.
In fact, for odd $n$ it defines a facet of the max cut polytope $P(K_n)$.
To determine how well the $k$th theta body captures this inequality, we can ask for the smallest $\lambda$ such that $\lambda - \sum x_{ij}$ is $k$-sos mod $I(\mathcal{C})$.
As $k$ increases, $\lambda$ will converge to the true minimum $\lfloor \frac{n^2}{4} \rfloor$.

In the case $G = K_n$, we can define another model of cuts, the {\em vertex model}. 
Let $C$ be a cut arising from a partition $[A,B]$ of vertices.
Associate to $C$ the characteristic vector $\chi_A \in \HHH = \{0,1\}^n$, the unit hypercube.
This preserves all the information contained in $C$: given a vector $y \in \HHH$, we can recover $A = \{i \in [n]: y_i = 1\}$ and $B = [n] \setminus A$.
Note that the cut $C$ also arises from the partition $[B,A]$, so each cut is represented by two vectors in $\HHH$.
We can translate between the vertex and edge models.
Given a point $y \in \HHH$, define $x = \tau(y)\in \{0,1\}^{n \choose 2}$ by $x_{ij} = (y_i - y_j)^2$.
This transformation converts cuts represented by the vertex model to cuts represented by the dge model; if $y_i = y_j$, then the edge $(ij)$ is not a cut edge so $x_{ij}=0$.
If $y_i \ne y_j$, then $(ij)$ is a cut edge, and indeed $x_{ij} = (y_i-y_j)^2 = 1$.

Recall that $f(x) = \lfloor \frac{n^2}{4} \rfloor - \sum x_{ij}$ defines a facet of the max cut polytope $P(K_n)$ in the edge model.
It turns out that $g(y) = (\lfloor \frac{n}{2} \rfloor - \sum y_i)(\lceil \frac{n}{2} \rceil - \sum y_i)$ defines this same function on the vertex model under the correspondence given by $\tau$.
To see this, one may apply $\tau$ and reason algebraically.
Alternatively, this can be seen by considering a cut $C = [A,B]$ represented by $x$ and $y$, and evaluating $f(x) = g(y)$ by hand.
Results about the sum of squares rank of $g(y)$ can be converted into results about $f(x)$.
If $f(x)$ is $k$-sos mod $I(\mathcal{C})$ for some $k$, the sum of squares can be written in the variables $x_{ij}$.
Writing the same sum of squares expression, substituting $(y_i - y_j)^2$ for $x_{ij}$ everywhere, shows that $g(y)$ is also $k$-sos mod $I(\HHH)$.
Thus the max cut problem is an example of optimizing a polynomial over the hypercube $\HHH$.

In this paper we will consider the general problem of optimizing a polynomial function over the hypercube $\HHH$. 
We will consider functions on the hypercube $\HHH$ satisfying certain properties.
First, since the ideal $I = I(\HHH) = \langle x_i^2 - x_i ;\, 1 \le i \le n\rangle$, each function $f \in \RR[\HHH] = \RR[x] / I$ can be represented using squarefree monomials.
This gives a notion of {\em degree} mod $I$ which coincides with the notion of degree we have used in the definition of $k$-sos.
This leads to a notion of {\em proper divisibility} mod $I$ in which $f$ is properly divisible by $g$ mod $I$ if there exists $h$ such that $f=gh$ mod $I$ and $\deg(f) = \deg(g) + \deg(h)$.
Here $f,g,h \in \RR[\HHH]$.
We also consider the symmetric group $S_n$ acting on $\RR[\HHH]$ by permuting variables.
A function $f \in \RR[\HHH]$ is {\em invariant} if it is fixed by $S_n$.
An invariant function has the same value on each {\em level} $\{x \in \HHH: \sum x_i = t \}$ of the hypercube, and is determined by these values.
We say that $f$ {\em vanishes to degree $k$ on level $t$} if $f$ is properly divisible by $(\sum x_i - t)^k$ but not by $(\sum x_i - t)^{k+1}$.

We also define a generalization of $k$-sos mod $I$ from Section \ref{section:cosos}.
This notion is denoted $(d_1,d_2)$-sos mod $I$, or being {\em $d_2$-sos with $d_1$-sos multipliers}.
A function $f \in \RR[\HHH]$ is said to be $(d_1,d_2)$-sos mod $I$ if there exist $g_1,g_2 \in \RR[\HHH]$, with $g_1 > 0$ on $\HHH$, such that $g_i$ is $d_i$-sos mod $I$, and $fg_1=g_2$.
Since any $f$ which is $(d_1,d_2)$-sos mod $I$ is also nonnegative on $\HHH$, this leads to a generalization of the theta body heirarchy which can still be optimized over in polynomial time.

\subsection{Background}
A previous semidefinite approximation to the max cut problem was given by Goemans and Williamson \cite{goemans_williamson}.
They used semidefinite programming to construct a randomized algorithm that produces solutions with objective value at least $0.878$ times the true optimum.
However, since the max cut problem is NP-hard, an exact semidefinite algorithm should not be efficient.
Indeed, Laurent \cite{moniquestuff} showed that the Lasserre relaxations of the max cut polytope $P(K_n)$, equivalent to the theta body heirarchy in this case, do not capture the facet $\lfloor \frac{n^2}{4} \rfloor - \sum x_{ij} \ge 0$ until at least the $n/4$th step of the heirarchy.

The idea of sums of squares multipliers came from work in real algebraic geometry, where the same idea is considered for polynomials on $\RR^n$.
It is a celebrated result of Hilbert \cite{hilbert} that for homogeneous polynomials $f$ in $n$ variables of even degree $d$, the implication
$$\hbox{\em $f \ge 0$ everywhere if and only if $f$ is a sum of squares}$$
holds exactly for $d=2$,$n=2$, and the special case $(n,d)=(3,4)$.
In all other cases, being a sum of squares implies nonnegativity, but not conversely.
Artin \cite{artin} generalized this result by showing that every nonnegative polynomial can be written as a sum of squares using sum of squares multipliers as discussed above.
Upper bounds are known for the degrees of these multipliers, but no lower bounds are known so far. %FIXME

\subsection{Results}
Our main results are as follows.
\begin{itemize}
\item Let $f$ be an invariant function on $\HHH$ which vanishes to odd degree on level $t$, for some $t \le n/2$ with $\deg (f) \le t$. 
Then $f$ is not $k$-sos mod $I$ for $k \le t$.
To show this, we consider the vector space $\RR[\HHH]$ as an {\em $S_n$-module} and decompose it into {\em irreducible representations}.
Most of these irreducible representations cannot contribute to a sum of squares which vanishes on level $t$.
The ones that can contribute each introduce a factor of $(t - \sum x_i)$ of even degree, leading to a parity contradiction.
\item As a corollary, we show that such an $f$ is not $(d_1,d_2)$-sos for $d_1,d_2 \le t$.
\item We reprove the result of Laurent, mentioned in the Background and used in Chapter \ref{chap:kicover}, that the theta body heirarchy does not converge to the max cut polytope $P(K_n)$ until at least the $n/4$th step.
To do this, we use the translation between the vertex and edge models of max cuts on $K_n$.
The function $g(y)$ is invariant and vanishes on level $t = \lfloor n/2 \rfloor$.
Therefore it cannot be a sum of squares of degree $\le n/2$.
\item We give an explicit example of a degree-4 polynomial on $\mathbb{R}^n$ which is nonnegative, but requires sum of squares multipliers of degree at least $n/2$ to be written as a sum of squares.
This polynomial is actually $g(y)$, extended from $\HHH$ to $\mathbb{R}^n$ by adding a positive scalar multiple of the sum of the ideal generators $\sum (y_i^2 - y_i)^2$.
That is, we use $h(y) = g(y) + \lambda \sum (y_i^2 - y_i)^2$ for a small $\lambda > 0$.
This gives a new constructive example of a polynomial that requires degree-$O(n)$ sum of squares multipliers.
\end{itemize}

\subsection{Comments}
For a fixed $f$, the question of whether $f$ is $(d_1,d_2)$-sos can be solved by semidefinite programming (either mod $I$ or globally).
However, we lose the ability to optimize the constant coefficient of $f$ such that $f$ is $(d_1,d_2)$-sos, as introducing sos multipliers changes the problem to quadratic optimization, which is NP-hard.
This doesn't affect complexity considerations, as in general we have a bound on the quantity we want to optimize (e.g. it is known a priori to lie in some interval $[0,C]$).
Then, we can use binary search to home in on the value to any fixed precision.
However, it is still an interesting geometric question whether the set $\Sigma_{d_1,d_2}$ of $(d_2,d_2)$-sos functions is the feasible region of a semidefinite program. %FIXME

The representation-theoretic decomposition of $\RR[\HHH]$ in this chapter can be performed in a wider setting.
For example, we performed calculations by hand indicating that the {\em matching polytope} of $K_9$ does not equal its second theta body.
Carrying these out for general $n$ and more complicated varieties will require more sophisticated representation theory.
We give a partial example of this in Chapter \ref{chap:matchings}.


\section{The Representation Theory of Matchings}
Chapter \ref{chap:matchings} is taken from a paper co-authored with Monty McGovern, currently being written. %FIXME
It describes the decomposition of the space of matchings on $K_n$ into irreducible representations of $S_n$.

\subsection{Problem Description}
A {\em perfect matching} in a graph $G=(V,E)$ is a subset $M \subseteq E$ such that each $v \in V$ meets some $e \in M$, and where each pair $e_1,e_2 \in M$ is disjoint.
Let $\MMM_{n}$ be the set of all perfect matchings in the complete graph $K_{2n}$.
The symmetric group $S_{2n}$ acts naturally on $\MMM_{n}$ by permuting the labels of vertices.
We wish to decompose $\CC[\MMM_{n}]$ into {\em irreducible representations} of $S_{2n}$.

We quickly recall the necessary concepts from representation theory.
A {\em representation} of a group $G$ is a vector space $V$ on which $G$ acts by linear transformations: that is, a group homomorphism $\rho: G \to GL(V)$.
A {\em subrepresentation} of $V$ is a vector subspace $W \subseteq V$ for which $GW = W$.
A representation $V$ is {\em irreducible} if the only subrepresentations of $V$ are 0 and $V$ itself.
For the symmetric group $S_n$, the irreducible representations are called the {\em Specht modules} $S^\lambda$ and are in bijection with the partitions $\lambda$ of $n$.
For their construction, see the textbooks \cite{Sagan} and \cite{Fulton}.

Suppose $V$ is a representation of a group $G$, and $H$ is a subgroup of $G$.
We can make $V$ into a representation of $H$ by simply forgetting the elements of $G \setminus H$; this operation is known as {\em restriction} and is denoted $\textup{Res}^G_H(V)$.
A similar operation is {\em induction}.
Here, we are given a group $G$, a subgroup $H$, and a representation $V$ of $H$.
We wish to construct a representation $\textup{Ind}_H^G(V)$ in a canonical way.
The details are more involved than for restriction, but it turns out to be possible.
The theorem we need here is the {\em Branching rule}, that $\textup{Res}_{S_{n-1}}^{S^n}(S^\lambda) = \sum_{\lambda^-} S^{\lambda^-}$ and $\textup{Ind}_{S_{n-1}}^{S^n}(S^\lambda) = \sum_{\lambda^+} S^{\lambda^+}$.
The sums $\lambda^-$ and $\lambda^+$ range over all partitions obtained from $\lambda$ by removing, respectively adding, a single cell.

\subsection{Background}
In \cite{bv} Barbasch and Vogan showed that $\CC[\MMM_{n}] \cong \oplus_\lambda S^\lambda$, where the sum is over all partitions $\lambda \vdash 2n$ consisting of even parts.
Their key lemma uses the restriction and induction operations to link the $n-1$ and $n$ cases of the theorem:
$$ \textup{Ind}_{S_{2n-2}}^{S_{2n-1}}(\CC[\MMM_{n-1}]) \cong \textup{Res}_{S_{2n-1}}^{S_{2n}}( \CC[\MMM_{n}]).$$ 
From this lemma, it is straightforward to use induction on $n$ to prove the desired decomposition of $\CC[\MMM_{n}]$.

From the perspective of representation theory, this settles the matter, because it describes $\CC[\MMM_{n}]$ up to isomorphism.
However, to use this in determining sums of squares mod $I$, we need to know the explicit decomposition of $\CC[\MMM_{n}]$ into irreducible representations.
That is, for each valid $\lambda \vdash 2n$, we require an embedding $S^\lambda \to \CC[\MMM_{n}]$.
From Barbasch and Vogan, we know such a map exists, but not necessarily how to find it.

A natural idea is to ``increase 2 to $m$'' in the definition of matching.
There are two natural ways to do this: perfect matchings on hypergraphs, and permutations of cycle type $(m^n)$. We describe hypergraphs first.

An {\em $m$-uniform hypergraph} is a collection $G = (V,E)$ of vertices and edges, where an edge is a collection of $m$ vertices.
The case $m=2$ gives the usual definition a graph.
The complete $m$-uniform hypergraph $K^{(m)}_n = ([n],{{[n]} \choose m})$.
A perfect matching in $K^{(m)}_{mn}$ is a collection of $n$ disjoint edges whose union is $[mn]$.
Equivalently, it is a set partition of $[mn]$ into $n$ sets of size $m$.
Let $\MMM_{m,n}$ be the set of all matchings in $K^{(m)}_n$.

The second generalization is based on permutations of a fixed {\em cycle type}.
Let $\ZZZ_{m,n} \subset S_{mn}$ be the set of all permutations consisting of $n$ disjoint $m$-cycles, such as $(12)(34)(56)(78)$ for $n=4,m=2$.
Let $S_{mn}$ act on $\ZZZ_{m,n}$ by conjugation: $\sigma \cdot \tau := \sigma \tau \sigma^{-1}$ for $\sigma \in S_{mn}$, $\tau \in \ZZZ_{m,n}$.
It turns out that $\CC[\MMM_n] \cong \CC[\ZZZ_{2,n}]$; for example, the permutation $(12)(34)(56)(78) \in \ZZZ_{2,4}$ is mapped to the matching also written $(12)(34)(56)(78)$.
This suggests an alternate generalization of $\CC[\MMM_n]$.
Fix $m$ and let $\ZZZ_{m,n}$ be the set of all permutations in $S_{mn}$ of cycle type $m^n$.
For example, when $(m,n) = (4,3)$, an example is $(1234)(5678)(9,10,11,12)$.

\subsection{Results}
\begin{itemize}
\item We find an explicit isomorphism between $\CC[\MMM_{n}]$ and $\oplus_\lambda S^\lambda$.
To construct the isomorphism, we give a map from each $S^\lambda$ to $\CC[\MMM_{n}]$ by imposing a matching structure on the elements of $S^\lambda$.
We check that this map is injective; by the Barbasch-Vogan result, it is an isomorphism.
\item We also extend the induction lemma in Barbasch and Vogan's proof to both of our generalized cases:
\begin{align*}
 \textup{Ind}_{S_{m(n-1)} \times S_{m-1}}^{S_{mn-1}}(\CC[\MMM_{m,n-1}] \otimes 1) & \cong \textup{Res}_{S_{mn-1}}^{S_{mn}}( \CC[\MMM_{m,n}]) \\
 \textup{Ind}_{S_{m(n-1)} }^{S_{mn-1}}(\CC[\ZZZ_{m,n-1}] \otimes 1) & \cong \textup{Res}_{S_{mn-1}}^{S_{mn}}( \CC[\ZZZ_{m,n}])
\end{align*}
We use this lemma to compute the decompositions of $\CC[\MMM_{m,n}]$ and $\CC[\ZZZ_{m,n}]$ for small values of $m$ and $n$.
\end{itemize}

\subsection{Comments}
We extended the induction lemma to both of our generalized cases.
By analogy with the case $m=2$, one might guess that $\CC[\MMM_{m,n}]$ or $\CC[\ZZZ_{m,n}]$ would be isomorphic to $\oplus_\lambda S^\lambda$, where the sum is over all $\lambda \vdash mn$ with all parts divisible by $m$.
In fact, even for $(m,n)=(3,2)$ we get $\CC[\MMM_{3,2}] \cong S^{(6}) + S^{(4,2)}$ instead of $S^{(6}) + S^{(3,3)}$ as conjectured.
The decomposition of $\CC[\ZZZ_{3,2}]$ is even further from the conjectured $(6),(3,3)$, instead consisting of the partitions $(6), (2, 1, 1, 1, 1), (2, 2, 2), (4, 2), (3, 1, 1, 1)$, and $(4, 1, 1)$, each with multiplicity 1.
Thus far we have not been able to find the pattern behind the decomposition.
However, if a pattern is identified, it should be straightforward to use the generalized induction lemma to prove it.


\section{A Note on Notation}
The following chapters were published as separate papers, and in some cases refer to different aspects of the same or related problems. 
As such, the chapters use different notation to fit the topic at hand, so the same object may have different names in different chapters.
